{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando nav\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.page_load_strategy = 'eager'  # Não espera o carregamento completo\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "driver.implicitly_wait(12)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquivo JSON\n",
    "json_file = 'noticias.json'\n",
    "\n",
    "# Verifica se o arquivo já existe e carrega o conteúdo, caso contrário cria uma lista vazia\n",
    "if os.path.exists(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        noticias = json.load(file)\n",
    "else:\n",
    "    noticias = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = r\"https://somosfanaticos.fans/br/noticias-recentes\"\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m links \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     link \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m//*[@id=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__next\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]/main/div[2]/div/div/article[\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m]/figure/a\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     links\u001b[38;5;241m.\u001b[39mappend(link)\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:748\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    745\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    746\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:352\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    350\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:306\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    304\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    305\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:326\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    323\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 326\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    136\u001b[0m         method,\n\u001b[0;32m    137\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukv7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "links = []\n",
    "for i in range(10):\n",
    "    link = driver.find_element('xpath', f'//*[@id=\"__next\"]/main/div[2]/div/div/article[{i+1}]/figure/a').get_attribute('href')\n",
    "    links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número máximo de tentativas\n",
    "# Somos fanáticos\n",
    "max_tentativas = 2\n",
    "\n",
    "# Número de tentativas já realizadas\n",
    "tentativa = 0\n",
    "\n",
    "while tentativa < max_tentativas:\n",
    "    try:\n",
    "        tentativa += 1\n",
    "        print(f\"Tentativa {tentativa} de {max_tentativas}\")\n",
    "\n",
    "        # Carrega o arquivo JSON e os títulos existentes a cada iteração para garantir que tudo está sendo atualizado\n",
    "        if os.path.exists(json_file):\n",
    "            with open(json_file, 'r', encoding='utf-8') as file:\n",
    "                noticias = json.load(file)\n",
    "        \n",
    "        # Extrai os títulos já presentes no arquivo para verificar notícias duplicadas\n",
    "        titulos_existentes = {noticia['titulo'] for noticia in noticias}\n",
    "        driver.get(\"https://somosfanaticos.fans/br/noticias-recentes\")\n",
    "        link = driver.find_element('xpath', f'//*[@id=\"__next\"]/main/div[2]/div/div/article[1]/figure/a').get_attribute('href')\n",
    "        \n",
    "        ap = driver.find_element('xpath', '/html/body/div[2]/main/div[2]/div/div/article[1]/div/a/span').get_attribute('innerText')\n",
    "        ap = ap.upper()\n",
    "        x = 2\n",
    "        while ap == \"APOSTAS\":\n",
    "            link = driver.find_element('xpath', f'//*[@id=\"__next\"]/main/div[2]/div/div/article[{x}]/figure/a').get_attribute('href')\n",
    "            ap = driver.find_element('xpath', f'/html/body/div[2]/main/div[2]/div/div/article[{x}]/div/a/span').get_attribute('innerText')\n",
    "            ap = ap.upper()\n",
    "            x += 1\n",
    "        driver.get(link)\n",
    "        titulo = driver.find_element('xpath', '/html/body/main/div[1]/section/article/div[1]/div[2]/h1').get_attribute('innerText')\n",
    "\n",
    "        # Verifica se o título já está no arquivo JSON\n",
    "        if titulo not in titulos_existentes:\n",
    "            # Se a notícia não estiver no arquivo, coleta o restante das informações\n",
    "            subtitulo = driver.find_element('xpath', f'/html/body/main/div[1]/section/article/div[1]/div[2]/h2').get_attribute('innerText')\n",
    "            autor = driver.find_element('xpath', f'/html/body/main/div[1]/section/article/div[1]/div[2]/div/div[1]/div').get_attribute('innerText')\n",
    "            try:\n",
    "                img = driver.find_element(\"xpath\", f'/html/body/main/div[1]/section/article/div[1]/figure/img').get_attribute('srcset')\n",
    "                descrimg = driver.find_element(\"xpath\", f'/html/body/main/div[1]/section/article/div[1]/figure/img').get_attribute('alt')\n",
    "            except:\n",
    "                img = \"Sem imagem\"\n",
    "                descrimg = \"Sem imagem\"\n",
    "            conteudo = driver.find_elements('xpath', f'/html/body/main/div[1]/section/article//p | /html/body/main/div[1]/section/article//h2 | /html/body/main/div[1]/section/article//h3')\n",
    "\n",
    "            conteudo_filtrado = []  # Lista para armazenar o conteúdo filtrado\n",
    "            skip_next = False  # Flag para pular o próximo índice\n",
    "\n",
    "            for Y, x in enumerate(conteudo):    \n",
    "                text = x.text.strip()\n",
    "            \n",
    "                if skip_next:  # Se a flag estiver ativada, pula o índice\n",
    "                    skip_next = False\n",
    "                    continue\n",
    "\n",
    "                # Ignorar conteúdo com base nas condições\n",
    "                if text == \"\":  # Verifica se o conteúdo é vazio\n",
    "                    print(f\"Ignorando índice {Y} devido a conteúdo vazio\")\n",
    "                    continue\n",
    "\n",
    "                if \"JÁ VOTARAM\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'JÁ VOTARAM'\")\n",
    "                    continue \n",
    "\n",
    "                if \"VEJA TAMBÉM\" in text:\n",
    "                    print(f\"Ignorando índice {Y} e o próximo devido a 'VEJA TAMBÉM'\")\n",
    "                    skip_next = True  # Define a flag para pular o próximo índice\n",
    "                    continue\n",
    "\n",
    "                if \"LEIA TAMBÉM\" in text:\n",
    "                    print(f\"Ignorando índice {Y} e o próximo devido a 'VEJA TAMBÉM'\")\n",
    "                    skip_next = True  # Define a flag para pular o próximo índice\n",
    "                    break\n",
    "                \n",
    "                if \"dizem os Fanáticos\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'dizem os Fanáticos'\")\n",
    "                    continue\n",
    "\n",
    "                if \"Siga o canal do Somos\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'Siga o canal do Somos'\")\n",
    "                    continue\n",
    "            \n",
    "                conteudo_filtrado.append(text)  # Adiciona o conteúdo\n",
    "\n",
    "            # Cria um dicionário com as informações da notícia\n",
    "            noticia = {\n",
    "                \"titulo\": titulo,\n",
    "                \"subtitulo\": subtitulo,\n",
    "                \"autor\": autor,\n",
    "                \"img\": img,\n",
    "                \"descrimg\": descrimg,\n",
    "                \"conteudo\": conteudo_filtrado\n",
    "            }\n",
    "\n",
    "            # Adiciona a nova notícia ao array de notícias\n",
    "            noticias.append(noticia)\n",
    "\n",
    "            # Salva o arquivo JSON com a nova notícia imediatamente\n",
    "            with open(json_file, 'w', encoding='utf-8') as file:\n",
    "                json.dump(noticias, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"\\nNotícia adicionada ao JSON - {titulo}\")\n",
    "            print(\"==========================================================================================\")\n",
    "            \n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        else:\n",
    "            print(f\"Notícia '{titulo}' já existe no arquivo. Ignorando...\")\n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "\n",
    "        # Se o código for executado sem exceções, sai do loop\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro encontrado: {e}\")\n",
    "        print(\"Tentando novamente...\\n\")\n",
    "        time.sleep(3)  # Espera 3 segundos antes de tentar novamente\n",
    "\n",
    "if tentativa == max_tentativas:\n",
    "    print(\"Número máximo de tentativas atingido. Buscando no próximo site...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número máximo de tentativas\n",
    "# Antenados no futebol\n",
    "max_tentativas = 2\n",
    "\n",
    "# Número de tentativas já realizadas\n",
    "tentativa = 0\n",
    "\n",
    "while tentativa < max_tentativas:\n",
    "    try:\n",
    "        tentativa += 1\n",
    "        print(f\"Tentativa {tentativa} de {max_tentativas}\")\n",
    "\n",
    "        # Extrai os títulos já presentes no arquivo para verificar notícias duplicadas\n",
    "        titulos_existentes = {noticia['titulo'] for noticia in noticias}\n",
    "\n",
    "        driver.get(\"https://www.antenadosnofutebol.com.br/latest-news\")\n",
    "        link = driver.find_element('xpath', f'//*[@id=\"__next\"]/main/div[2]/div/div/article[1]/figure/a').get_attribute('href')\n",
    "        ap = driver.find_element('xpath', '//*[@id=\"__next\"]/main/div[2]/div/div/article[1]/div/a/span').get_attribute('innerText')\n",
    "        ap = ap.upper()\n",
    "        x = 2\n",
    "        while ap == \"APOSTAS\":\n",
    "            link = driver.find_element('xpath', f'//*[@id=\"__next\"]/main/div[2]/div/div/article[{x}]/figure/a').get_attribute('href')\n",
    "            ap = driver.find_element('xpath', f'//*[@id=\"__next\"]/main/div[2]/div/div/article[{x}]/div/a/span').get_attribute('innerText')\n",
    "            ap = ap.upper()\n",
    "            x += 1\n",
    "\n",
    "        driver.get(link)\n",
    "        titulo = driver.find_element('xpath', f'/html/body/main/div[2]/section/article/div[1]/div[2]/h1').get_attribute('innerText')\n",
    "\n",
    "        # Verifica se o título já está no arquivo JSON\n",
    "        if titulo not in titulos_existentes:\n",
    "            # Se a notícia não estiver no arquivo, coleta o restante das informações\n",
    "            subtitulo = driver.find_element('xpath', f'/html/body/main/div[2]/section/article/div[1]/div[2]/h2').get_attribute('innerText')\n",
    "            autor = driver.find_element('xpath', f'/html/body/main/div[2]/section/article/div[1]/div[2]/div/div[1]/div/p[1]/a').get_attribute('innerText')\n",
    "            try:\n",
    "                img = driver.find_element(\"xpath\", f'/html/body/main/div[2]/section/article/div[1]/figure/img').get_attribute('srcset')\n",
    "                descrimg = driver.find_element(\"xpath\", f'/html/body/main/div[2]/section/article/div[1]/figure/figcaption').get_attribute('innerText')\n",
    "            except:\n",
    "                img = \"Sem imagem\"\n",
    "                descrimg = \"Sem imagem\"\n",
    "            conteudo = driver.find_elements('xpath', f'/html/body/main/div[2]/section/article//p | /html/body/main/div[2]/section/article//h2 | /html/body/main/div[2]/section/article//h3')\n",
    "\n",
    "            conteudo_filtrado = []  # Lista para armazenar o conteúdo filtrado\n",
    "            skip_next = False  # Flag para pular o próximo índice\n",
    "\n",
    "            for Y, x in enumerate(conteudo):    \n",
    "                text = x.text.strip()\n",
    "            \n",
    "                if skip_next:  # Se a flag estiver ativada, pula o índice\n",
    "                    skip_next = False\n",
    "                    continue\n",
    "\n",
    "                # Ignorar conteúdo com base nas condições\n",
    "                if text == \"\":  # Verifica se o conteúdo é vazio\n",
    "                    print(f\"Ignorando índice {Y} devido a conteúdo vazio\")\n",
    "                    continue\n",
    "\n",
    "                if \"JÁ VOTARAM\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'JÁ VOTARAM'\")\n",
    "                    continue \n",
    "\n",
    "                if \"VEJA TAMBÉM\" in text:\n",
    "                    print(f\"Ignorando índice {Y} e o próximo devido a 'VEJA TAMBÉM'\")\n",
    "                    skip_next = True  # Define a flag para pular o próximo índice\n",
    "                    continue  \n",
    "                if \"LEIA TAMBÉM\" in text:\n",
    "                    print(f\"Ignorando índice {Y} e o próximo devido a 'LEIA TAMBÉM'\")\n",
    "                    skip_next = True  # Define a flag para pular o próximo índice\n",
    "                    break  \n",
    "                \n",
    "                if \"dizem os Fanáticos\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'dizem os Fanáticos'\")\n",
    "                    continue  \n",
    "\n",
    "                if \"Siga o canal do Somos\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'Siga o canal do Somos'\")\n",
    "                    continue  \n",
    "            \n",
    "                conteudo_filtrado.append(text)  # Adiciona o conteúdo\n",
    "\n",
    "            # Cria um dicionário com as informações da notícia\n",
    "            noticia = {\n",
    "                \"titulo\": titulo,\n",
    "                \"subtitulo\": subtitulo,\n",
    "                \"autor\": autor,\n",
    "                \"img\": img,\n",
    "                \"descrimg\": descrimg,\n",
    "                \"conteudo\": conteudo_filtrado\n",
    "            }\n",
    "\n",
    "            # Adiciona a nova notícia ao array de notícias\n",
    "            noticias.append(noticia)\n",
    "\n",
    "            # Salva o arquivo JSON com a nova notícia imediatamente\n",
    "            with open(json_file, 'w', encoding='utf-8') as file:\n",
    "                json.dump(noticias, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"\\nNotícia adicionada ao JSON - {titulo}\")\n",
    "            print(\"==========================================================================================\")\n",
    "            \n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        else:\n",
    "            print(f\"Notícia '{titulo}' já existe no arquivo. Ignorando...\")\n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "\n",
    "        # Se o código for executado sem exceções, sai do loop\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro encontrado: {e}\")\n",
    "        print(\"Tentando novamente...\\n\")\n",
    "        time.sleep(3)  # Espera 3 segundos antes de tentar novamente\n",
    "\n",
    "if tentativa == max_tentativas:\n",
    "    print(\"Número máximo de tentativas atingido. Buscando no próximo site...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número máximo de tentativas\n",
    "# BolaVip\n",
    "max_tentativas = 2\n",
    "\n",
    "# Número de tentativas já realizadas\n",
    "tentativa = 0\n",
    "\n",
    "while tentativa < max_tentativas:\n",
    "    try:\n",
    "        tentativa += 1\n",
    "        print(f\"Tentativa {tentativa} de {max_tentativas}\")\n",
    "\n",
    "        # Extrai os títulos já presentes no arquivo para verificar notícias duplicadas\n",
    "        titulos_existentes = {noticia['titulo'] for noticia in noticias}\n",
    "\n",
    "        driver.get(\"https://br.bolavip.com/noticias-recentes\")\n",
    "        link = driver.find_element('xpath', f'//*[@id=\"__next\"]/main/div[2]/div/div/article[1]/figure/a').get_attribute('href')\n",
    "        \n",
    "        ap = driver.find_element('xpath', '/html/body/div[1]/main/div[2]/div/div/article[1]/div/a/span').get_attribute('innerText')\n",
    "        ap = ap.upper()\n",
    "        x = 2\n",
    "        while ap == \"APOSTAS\" or ap == \"NFL\":\n",
    "            link = driver.find_element('xpath', f'//*[@id=\"__next\"]/main/div[2]/div/div/article[{x}]/figure/a').get_attribute('href')\n",
    "            ap = driver.find_element('xpath', f'/html/body/div[1]/main/div[2]/div/div/article[{x}]/div/a/span').get_attribute('innerText')\n",
    "            ap = ap.upper()\n",
    "            x += 1\n",
    "        driver.get(link)\n",
    "        titulo = driver.find_element('xpath', f'/html/body/main/div[2]/section[1]/div/article/div[1]/div[2]/h1').get_attribute('innerText')\n",
    "\n",
    "        # Verifica se o título já está no arquivo JSON\n",
    "        if titulo not in titulos_existentes:\n",
    "            # Se a notícia não estiver no arquivo, coleta o restante das informações\n",
    "            subtitulo = driver.find_element('xpath', f'/html/body/main/div[2]/section[1]/div/article/div[1]/div[2]/h2').get_attribute('innerText')\n",
    "            autor = driver.find_element('xpath', f'/html/body/main/div[2]/section[1]/div/article/div[1]/div[2]/div/div[1]/div/p[1]/a').get_attribute('innerText')\n",
    "            try:\n",
    "                img = driver.find_element(\"xpath\", f'/html/body/main/div[2]/section[1]/div/article/div[2]/figure/img').get_attribute('srcset')\n",
    "                descrimg = driver.find_element(\"xpath\", f'/html/body/main/div[2]/section[1]/div/article/div[2]/figure/figcaption').get_attribute('innerText')\n",
    "            except:\n",
    "                img = \"Sem imagem\"\n",
    "                descrimg = \"Sem imagem\"\n",
    "            conteudo = driver.find_elements('xpath', f'/html/body/main/div[2]/section[1]/div/article//p | /html/body/main/div[2]/section[1]/div/article//h2 | /html/body/main/div[2]/section[1]/div/article//h3')\n",
    "\n",
    "            conteudo_filtrado = []  # Lista para armazenar o conteúdo filtrado\n",
    "            skip_next = False  # Flag para pular o próximo índice\n",
    "\n",
    "            for Y, x in enumerate(conteudo):    \n",
    "                text = x.text.strip()\n",
    "            \n",
    "                if skip_next:  # Se a flag estiver ativada, pula o índice\n",
    "                    skip_next = False\n",
    "                    continue\n",
    "\n",
    "                # Ignorar conteúdo com base nas condições\n",
    "                if text == \"\":  # Verifica se o conteúdo é vazio\n",
    "                    print(f\"Ignorando índice {Y} devido a conteúdo vazio\")\n",
    "                    continue\n",
    "\n",
    "                if \"JÁ VOTARAM\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'JÁ VOTARAM'\")\n",
    "                    continue \n",
    "\n",
    "                if \"VEJA TAMBÉM\" in text:\n",
    "                    print(f\"Ignorando índice {Y} e o próximo devido a 'VEJA TAMBÉM'\")\n",
    "                    skip_next = True  # Define a flag para pular o próximo índice\n",
    "                    continue  \n",
    "                if \"LEIA TAMBÉM\" in text:\n",
    "                    print(f\"Ignorando índice {Y} e o próximo devido a 'LEIA TAMBÉM'\")\n",
    "                    skip_next = True  # Define a flag para pular o próximo índice\n",
    "                    break  \n",
    "                \n",
    "                if \"dizem os Fanáticos\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'dizem os Fanáticos'\")\n",
    "                    continue  \n",
    "\n",
    "                if \"Siga o canal do Somos\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'Siga o canal do Somos'\")\n",
    "                    continue  \n",
    "\n",
    "                if \"Google News\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'Siga o canal do Somos'\")\n",
    "                    continue  \n",
    "                if \"É um jornalista que\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'Siga o canal do Somos'\")\n",
    "                    continue  \n",
    "                if \"É jornalista há\" in text:\n",
    "                    print(f\"Ignorando índice {Y} devido a 'Siga o canal do Somos'\")\n",
    "                    continue  \n",
    "            \n",
    "                conteudo_filtrado.append(text)  # Adiciona o conteúdo\n",
    "\n",
    "            # Cria um dicionário com as informações da notícia\n",
    "            noticia = {\n",
    "                \"titulo\": titulo,\n",
    "                \"subtitulo\": subtitulo,\n",
    "                \"autor\": autor,\n",
    "                \"img\": img,\n",
    "                \"descrimg\": descrimg,\n",
    "                \"conteudo\": conteudo_filtrado\n",
    "            }\n",
    "\n",
    "            # Adiciona a nova notícia ao array de notícias\n",
    "            noticias.append(noticia)\n",
    "\n",
    "            # Salva o arquivo JSON com a nova notícia imediatamente\n",
    "            with open(json_file, 'w', encoding='utf-8') as file:\n",
    "                json.dump(noticias, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"\\nNotícia adicionada ao JSON - {titulo}\")\n",
    "            print(\"==========================================================================================\")\n",
    "            \n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        else:\n",
    "            print(f\"Notícia '{titulo}' já existe no arquivo. Ignorando...\")\n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "\n",
    "        # Se o código for executado sem exceções, sai do loop\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro encontrado: {e}\")\n",
    "        print(\"Tentando novamente...\\n\")\n",
    "        time.sleep(3)  # Espera 3 segundos antes de tentar novamente\n",
    "\n",
    "if tentativa == max_tentativas:\n",
    "    print(\"Número máximo de tentativas atingido. Buscando no próximo site...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número máximo de tentativas\n",
    "# Uol esportes\n",
    "max_tentativas = 2\n",
    "\n",
    "# Número de tentativas já realizadas\n",
    "tentativa = 0\n",
    "\n",
    "while tentativa < max_tentativas:\n",
    "    try:\n",
    "        tentativa += 1\n",
    "        print(f\"Tentativa {tentativa} de {max_tentativas}\")\n",
    "\n",
    "        # Extrai os títulos já presentes no arquivo para verificar notícias duplicadas\n",
    "        titulos_existentes = {noticia['titulo'] for noticia in noticias}\n",
    "\n",
    "        driver.get(\"https://www.uol.com.br/esporte/futebol/ultimas/\")\n",
    "        link = driver.find_element('xpath', f'/html/body/div[4]/section/section/div/div/div[1]/section/div/div/div/div/div[1]/div/a').get_attribute('href')\n",
    "        driver.get(link)\n",
    "        titulo = driver.find_element('xpath', f'/html/body/div[1]/main/article/div[1]/div[1]/div/div[1]/div/div[2]/div/h1').get_attribute('innerText')\n",
    "\n",
    "        # Verifica se o título já está no arquivo JSON\n",
    "        if titulo not in titulos_existentes:\n",
    "            # Se a notícia não estiver no arquivo, coleta o restante das informações\n",
    "            titulo = driver.find_element('xpath', '/html/body/div[1]/main/article/div[1]/div[1]/div/div[1]/div/div[2]/div/h1').get_attribute('innerText')\n",
    "            subtitulo = \"Sem subtitulo\"\n",
    "            autor = driver.find_element('xpath', '/html/body/div[1]/main/article/div[1]/div[1]/div/div[2]/div/div[1]/div').get_attribute('innerText')\n",
    "            try:\n",
    "                img = driver.find_element('xpath', '/html/body/div[1]/main/article/div[1]/div[2]/div/div/figure/figure/picture/img').get_attribute('src')\n",
    "                descrimg = driver.find_element('xpath', '/html/body/div[1]/main/article/div[1]/div[2]/div/div/figure/figure/picture/img').get_attribute('alt')\n",
    "            except:\n",
    "                img = \"Sem imagem\"\n",
    "                descrimg = \"Sem descrição\"\n",
    "                \n",
    "            conteudo1 = driver.find_elements('xpath', '/html/body/div[1]/main/article/div[1]/div[2]/div/div/div//p | /html/body/div[1]/main/article/div[1]/div[2]/div/div/div//h2')\n",
    "            conteudo2 = driver.find_elements('xpath', '/html/body/div[1]/main/article/div[2]/div/div/div/div[1]//p | /html/body/div[1]/main/article/div[2]/div/div/div/div[1]//h2')\n",
    "            \n",
    "            # Extraindo o texto dos elementos\n",
    "            conteudo1_texto = [element.text for element in conteudo1]\n",
    "            conteudo2_texto = [element.text for element in conteudo2]\n",
    "            \n",
    "            conteudo = conteudo1_texto + conteudo2_texto\n",
    "\n",
    "            # Cria um dicionário com as informações da notícia\n",
    "            noticia = {\n",
    "                \"titulo\": titulo,\n",
    "                \"subtitulo\": subtitulo,\n",
    "                \"autor\": autor,\n",
    "                \"img\": img,\n",
    "                \"descrimg\": descrimg,\n",
    "                \"conteudo\": conteudo\n",
    "            }\n",
    "\n",
    "            # Adiciona a nova notícia ao array de notícias\n",
    "            noticias.append(noticia)\n",
    "\n",
    "            # Salva o arquivo JSON com a nova notícia imediatamente\n",
    "            with open(json_file, 'w', encoding='utf-8') as file:\n",
    "                json.dump(noticias, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"\\nNotícia adicionada ao JSON - {titulo}\")\n",
    "            print(\"==========================================================================================\")\n",
    "            \n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        else:\n",
    "            print(f\"Notícia '{titulo}' já existe no arquivo. Ignorando...\")\n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        \n",
    "        # Se o código for executado sem exceções, sai do loop\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro encontrado: {e}\")\n",
    "        print(\"Tentando novamente...\\n\")\n",
    "        time.sleep(3)  # Espera 3 segundos antes de tentar novamente\n",
    "\n",
    "if tentativa == max_tentativas:\n",
    "    print(\"Número máximo de tentativas atingido. Encerrando o programa.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número máximo de tentativas\n",
    "# GE Globo Esporte\n",
    "# Não está funcionando.\n",
    "max_tentativas = 2\n",
    "tentativa = 0\n",
    "\n",
    "while tentativa < max_tentativas:\n",
    "    try:\n",
    "        tentativa += 1\n",
    "        print(f\"Tentativa {tentativa} de {max_tentativas}\")\n",
    "\n",
    "        # Extrai os títulos já presentes no arquivo para verificar notícias duplicadas\n",
    "        titulos_existentes = {noticia['titulo'] for noticia in noticias}\n",
    "\n",
    "        driver.get('https://ge.globo.com/')\n",
    "        \n",
    "        time.sleep(3)  # Aguardar o carregamento da página inicial\n",
    "\n",
    "        # Encontrar o link da notícia e acessar\n",
    "        for i in range(2, 4):\n",
    "            try:\n",
    "                descr = driver.find_element('xpath', f'/html/body/div[2]/main[3]/div[4]/div[2]/div/div/div/div/div/div/div/div[2]/div[1]/div/div/div[{i}]/div/div/div/div[4]/span[2]').get_attribute('innerText')\n",
    "                print(descr)\n",
    "            except:\n",
    "                continue\n",
    "            if descr == \"Tempo Real\":\n",
    "                print(\"Notícia em tempo real, passando para a próxima.\")\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    print(i)\n",
    "                    linkg = driver.find_element('xpath', f'/html/body/div[2]/main[3]/div[4]/div[2]/div/div/div/div/div/div/div/div[2]/div[1]/div/div/div[{i}]/div/div/div/div[2]/div/h2/a').get_attribute('href')\n",
    "                except:\n",
    "                    print(i)\n",
    "                    linkg = driver.find_element('xpath', f'/html/body/div[2]/main[3]/div[4]/div[2]/div/div/div/div/div/div/div/div[2]/div[1]/div/div/div[{i}]/div/div/div/div[3]/div/h2/a').get_attribute('href')\n",
    "            \n",
    "        time.sleep(1)  # Aguardar o carregamento da página da notícia\n",
    "        driver.get(linkg)\n",
    "        print(linkg)\n",
    "        # Coletar o título da notícia\n",
    "        titulo = driver.find_element('xpath', f'/html/body/div[2]/main/div[3]/div[1]/h1').get_attribute('innerText')\n",
    "        print('Pegou o título')\n",
    "\n",
    "        # Verifica se o título já está no arquivo JSON\n",
    "        if titulo not in titulos_existentes:\n",
    "            print('Conferiu no json')\n",
    "            # Se a notícia não estiver no arquivo, coleta o restante das informações\n",
    "            subtitulo = driver.find_element('xpath', '/html/body/div[2]/main/div[3]/div[2]/h2').get_attribute('innerText')\n",
    "            print('Pegou sub')\n",
    "            autor = driver.find_element('xpath', '/html/body/div[2]/main/div[4]/div[1]/div/div').get_attribute('innerText')\n",
    "            print('Pegou autor')\n",
    "            \n",
    "            for l in range(1, 20):\n",
    "                try:\n",
    "                    img = driver.find_element('xpath', f'/html/body/div[2]/main/div[5]/article/div[4]/div[{l}]/div/div/div/figure/amp-img/img').get_attribute('src')\n",
    "                    print('pegou imagem')\n",
    "                    descrimg = driver.find_element('xpath', '/html/body/div[2]/main/div[5]/article/div[4]/div[{l}]/div/div/div/figure/amp-img/img').get_attribute('alt')\n",
    "                except:\n",
    "                    img = \"Sem imagem\"\n",
    "                    descrimg = \"Sem descrição\"\n",
    "                \n",
    "            conteudo1 = driver.find_elements('xpath', '/html/body/div[2]/main/div[5]/article//p | /html/body/div[2]/main/div[5]/article//h2 | /html/body/div[2]/main/div[5]/article//ul | /html/body/div[2]/main/div[5]/article//blockquote | /html/body/div[2]/main/div[5]/article//span')\n",
    "            print('Pegou o conteúdo')\n",
    "            \n",
    "            # Extraindo o texto dos elementos e filtrando conteúdo vazio\n",
    "            conteudo_texto = [element.text for element in conteudo1 if element.text.strip()]\n",
    "            print('Extraiu o conteúdo dos elementos e filtrou')\n",
    "            \n",
    "            # Cria um dicionário com as informações da notícia\n",
    "            noticia = {\n",
    "                \"titulo\": titulo,\n",
    "                \"subtitulo\": subtitulo,\n",
    "                \"autor\": autor,\n",
    "                \"img\": img,\n",
    "                \"descrimg\": descrimg,\n",
    "                \"conteudo\": conteudo_texto\n",
    "            }\n",
    "\n",
    "            # Adiciona a nova notícia ao array de notícias\n",
    "            noticias.append(noticia)\n",
    "\n",
    "            # Salva o arquivo JSON com a nova notícia imediatamente\n",
    "            with open(json_file, 'w', encoding='utf-8') as file:\n",
    "                json.dump(noticias, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"\\nNotícia adicionada ao JSON - {titulo}\")\n",
    "            print(\"==========================================================================================\")\n",
    "            \n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        else:\n",
    "            print(f\"Notícia '{titulo}' já existe no arquivo. Ignorando...\")\n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        \n",
    "        # Se o código for executado sem exceções, sai do loop\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro encontrado: {e}\")\n",
    "        print(\"Tentando novamente...\\n\")\n",
    "        time.sleep(3)  # Espera 3 segundos antes de tentar novamente\n",
    "\n",
    "if tentativa == max_tentativas:\n",
    "    print(\"Número máximo de tentativas atingido. Encerrando o programa.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentativa 1 de 2\n",
      "\n",
      "Notícia adicionada ao JSON - Quem manda no futebol da Europa? Confira raio-X de clubes, empresas, investidores e \"SAFs\"\n",
      "==========================================================================================\n",
      "BUSCANDO PRÓXIMO SITE... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define o número máximo de tentativas\n",
    "# Globo Internacional\n",
    "max_tentativas = 2\n",
    "tentativa = 0\n",
    "\n",
    "while tentativa < max_tentativas:\n",
    "    try:\n",
    "        tentativa += 1\n",
    "        print(f\"Tentativa {tentativa} de {max_tentativas}\")\n",
    "\n",
    "        # Extrai os títulos já presentes no arquivo para verificar notícias duplicadas\n",
    "        titulos_existentes = {noticia['titulo'] for noticia in noticias}\n",
    "\n",
    "        driver.get('https://ge.globo.com/futebol/futebol-internacional/')\n",
    "        time.sleep(1)  # Aguardar o carregamento da página inicial\n",
    "\n",
    "        try:\n",
    "            link = driver.find_element('xpath', f'//*[@id=\"feed-placeholder\"]/div/div/div[2]/div/div/div/div[1]/div/div/div/div[3]/div/h2/a').get_attribute('href')\n",
    "        except:\n",
    "            try:\n",
    "                link = driver.find_element('xpath', f'/html/body/div[2]/main[3]/div[4]/div[2]/div/div/div/div/div/div/div/div[2]/div/div/div/div[1]/div/div/div/div[2]/div/h2/a').get_attribute('href')\n",
    "            except:\n",
    "                link = driver.find_element('xpath', f'/html/body/div[2]/main[3]/div[4]/div[2]/div/div/div/div/div/div/div/div[2]/div/div/div/div[2]/div/div/div/div[2]/div/h2/a').get_attribute('href')\n",
    "\n",
    "        # Acessar o link da notícia\n",
    "        driver.get(link)\n",
    "        time.sleep(1)  # Aguardar o carregamento da página da notícia\n",
    "\n",
    "        # Coletar o título da notícia\n",
    "        titulo = driver.find_element('xpath', f'/html/body/div[2]/main/div[3]/div[1]/h1').get_attribute('innerText')\n",
    "\n",
    "        # Verifica se o título já está no arquivo JSON\n",
    "        if titulo not in titulos_existentes:\n",
    "            # Se a notícia não estiver no arquivo, coleta o restante das informações\n",
    "            subtitulo = driver.find_element('xpath', '/html/body/div[2]/main/div[3]/div[2]/h2').get_attribute('innerText')\n",
    "            autor = driver.find_element('xpath', '/html/body/div[2]/main/div[4]/div[1]/div/div').get_attribute('innerText')\n",
    "            \n",
    "            try:\n",
    "                img = driver.find_element('xpath', '/html/body/div[2]/main/div[5]/article//img').get_attribute('src')\n",
    "                descrimg = driver.find_element('xpath', '/html/body/div[2]/main/div[5]/article//img').get_attribute('alt')\n",
    "            except:\n",
    "                img = \"Sem imagem\"\n",
    "                descrimg = \"Sem descrição\"\n",
    "                \n",
    "            conteudo1 = driver.find_elements('xpath', '/html/body/div[2]/main/div[5]/article//p | /html/body/div[2]/main/div[5]/article//h2 | /html/body/div[2]/main/div[5]/article//ul | /html/body/div[2]/main/div[5]/article//blockquote | /html/body/div[2]/main/div[5]/article//span')\n",
    "            \n",
    "            # Extraindo o texto dos elementos e filtrando conteúdo vazio\n",
    "            conteudo_texto = [element.text for element in conteudo1 if element.text.strip()]\n",
    "            \n",
    "            # Cria um dicionário com as informações da notícia\n",
    "            noticia = {\n",
    "                \"titulo\": titulo,\n",
    "                \"subtitulo\": subtitulo,\n",
    "                \"autor\": autor,\n",
    "                \"img\": img,\n",
    "                \"descrimg\": descrimg,\n",
    "                \"conteudo\": conteudo_texto\n",
    "            }\n",
    "\n",
    "            # Adiciona a nova notícia ao array de notícias\n",
    "            noticias.append(noticia)\n",
    "\n",
    "            # Salva o arquivo JSON com a nova notícia imediatamente\n",
    "            with open(json_file, 'w', encoding='utf-8') as file:\n",
    "                json.dump(noticias, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"\\nNotícia adicionada ao JSON - {titulo}\")\n",
    "            print(\"==========================================================================================\")\n",
    "            \n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        else:\n",
    "            print(f\"Notícia '{titulo}' já existe no arquivo. Ignorando...\")\n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "\n",
    "        # Se o código for executado sem exceções, sai do loop\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro encontrado: {e}\")\n",
    "        print(\"Tentando novamente...\\n\")\n",
    "        time.sleep(3)  # Espera 3 segundos antes de tentar novamente\n",
    "\n",
    "if tentativa == max_tentativas:\n",
    "    print(\"Número máximo de tentativas atingido. Encerrando o programa.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentativa 1 de 2\n",
      "\n",
      "Notícia adicionada ao JSON - Dorival Júnior faz balanço positivo do ano da Seleção: \"Muitas coisas mudaram\"\n",
      "==========================================================================================\n",
      "BUSCANDO PRÓXIMO SITE... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define o número máximo de tentativas\n",
    "max_tentativas = 2\n",
    "tentativa = 0\n",
    "\n",
    "while tentativa < max_tentativas:\n",
    "    try:\n",
    "        tentativa += 1\n",
    "        print(f\"Tentativa {tentativa} de {max_tentativas}\")\n",
    "\n",
    "        # Extrai os títulos já presentes no arquivo para verificar notícias duplicadas\n",
    "        titulos_existentes = {noticia['titulo'] for noticia in noticias}\n",
    "\n",
    "        driver.get('https://ge.globo.com/futebol/selecao-brasileira/')\n",
    "        time.sleep(1)  # Aguardar o carregamento da página inicial\n",
    "\n",
    "        # Acessar o link da notícia principal\n",
    "        try:\n",
    "            link = driver.find_element('xpath', '/html/body/div[2]/main[3]/div[4]/div[2]/div/div/div/div/div/div/div/div[2]/div/div/div/div[1]/div/div/div/div[2]/div/h2/a').get_attribute('href')\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao tentar encontrar o link da notícia: {e}\")\n",
    "            print(\"Tentando acessar um link alternativo...\")\n",
    "            continue  # Pula para a próxima tentativa\n",
    "\n",
    "        # Acessar o link da notícia\n",
    "        driver.get(link)\n",
    "        time.sleep(1)  # Aguardar o carregamento da página da notícia\n",
    "\n",
    "        # Coletar o título da notícia\n",
    "        titulo = driver.find_element('xpath', '/html/body/div[2]/main/div[3]/div[1]/h1').get_attribute('innerText')\n",
    "\n",
    "        # Verifica se o título já está no arquivo JSON\n",
    "        if titulo not in titulos_existentes:\n",
    "            # Se a notícia não estiver no arquivo, coleta o restante das informações\n",
    "            subtitulo = driver.find_element('xpath', '/html/body/div[2]/main/div[3]/div[2]/h2').get_attribute('innerText')\n",
    "            autor = driver.find_element('xpath', '/html/body/div[2]/main/div[4]/div[1]/div/div').get_attribute('innerText')\n",
    "            \n",
    "            try:\n",
    "                img = driver.find_element('xpath', '/html/body/div[2]/main/div[5]/article//img').get_attribute('src')\n",
    "                descrimg = driver.find_element('xpath', '/html/body/div[2]/main/div[5]/article//img').get_attribute('alt')\n",
    "            except:\n",
    "                img = \"Sem imagem\"\n",
    "                descrimg = \"Sem descrição\"\n",
    "                \n",
    "            conteudo1 = driver.find_elements('xpath', '/html/body/div[2]/main/div[5]/article//p | /html/body/div[2]/main/div[5]/article//h2 | /html/body/div[2]/main/div[5]/article//ul | /html/body/div[2]/main/div[5]/article//blockquote | /html/body/div[2]/main/div[5]/article//span')\n",
    "            \n",
    "            # Extraindo o texto dos elementos e filtrando conteúdo vazio\n",
    "            conteudo_texto = [element.text for element in conteudo1 if element.text.strip()]\n",
    "            \n",
    "            # Cria um dicionário com as informações da notícia\n",
    "            noticia = {\n",
    "                \"titulo\": titulo,\n",
    "                \"subtitulo\": subtitulo,\n",
    "                \"autor\": autor,\n",
    "                \"img\": img,\n",
    "                \"descrimg\": descrimg,\n",
    "                \"conteudo\": conteudo_texto\n",
    "            }\n",
    "\n",
    "            # Adiciona a nova notícia ao array de notícias\n",
    "            noticias.append(noticia)\n",
    "\n",
    "            # Salva o arquivo JSON com a nova notícia imediatamente\n",
    "            with open(json_file, 'w', encoding='utf-8') as file:\n",
    "                json.dump(noticias, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"\\nNotícia adicionada ao JSON - {titulo}\")\n",
    "            print(\"==========================================================================================\")\n",
    "            \n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        else:\n",
    "            print(f\"Notícia '{titulo}' já existe no arquivo. Ignorando...\")\n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "\n",
    "        # Se o código for executado sem exceções, sai do loop\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro encontrado: {e}\")\n",
    "        print(\"Tentando novamente...\\n\")\n",
    "        time.sleep(3)  # Espera 3 segundos antes de tentar novamente\n",
    "\n",
    "if tentativa == max_tentativas:\n",
    "    print(\"Número máximo de tentativas atingido. Encerrando o programa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentativa 1 de 2\n",
      "\n",
      "Notícia adicionada ao JSON - Thiago Silva faz forte desabafo após empate, e Mano Menezes pede cautela em relação aos jovens\n",
      "==========================================================================================\n",
      "BUSCANDO PRÓXIMO SITE... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define o número máximo de tentativas\n",
    "max_tentativas = 2\n",
    "tentativa = 0\n",
    "\n",
    "while tentativa < max_tentativas:\n",
    "    try:\n",
    "        tentativa += 1\n",
    "        print(f\"Tentativa {tentativa} de {max_tentativas}\")\n",
    "\n",
    "        # Extrai os títulos já presentes no arquivo para verificar notícias duplicadas\n",
    "        titulos_existentes = {noticia['titulo'] for noticia in noticias}\n",
    "\n",
    "        # Acessa a página principal de esportes do IG\n",
    "        driver.get(\"https://esporte.ig.com.br/futebol/\")\n",
    "        time.sleep(2)  # Aguardar o carregamento da página inicial\n",
    "\n",
    "        # Localiza o link da notícia principal e acessa\n",
    "        try:\n",
    "            link = driver.find_element('xpath', '/html/body/main/div/div[1]/div/div[3]/div/div/div/div/ul[1]/li[1]/a').get_attribute('href')\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao tentar encontrar o link da notícia: {e}\")\n",
    "            print(\"Tentando acessar um link alternativo...\")\n",
    "            link = driver.find_element('xpath', '/html/body/main/div/div[1]/div/div[2]/div/div/div/div/ul[1]/div[2]/a').get_attribute('href')\n",
    "            continue  # Pula para a próxima tentativa\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(1)  # Aguardar o carregamento da página da notícia\n",
    "\n",
    "        # Coleta o título da notícia\n",
    "        titulo = driver.find_element('xpath', '/html/body/div[3]/div/div[1]/h1').get_attribute('innerText')\n",
    "\n",
    "        # Verifica se o título já está no arquivo JSON\n",
    "        if titulo not in titulos_existentes:\n",
    "            # Se a notícia não estiver no arquivo, coleta o restante das informações\n",
    "            subtitulo = driver.find_element('xpath', '/html/body/div[3]/div/div[1]/h2').get_attribute('innerText')\n",
    "            autor = driver.find_element('xpath', '/html/body/div[3]/div/div[4]/div/div').get_attribute('innerText')\n",
    "            \n",
    "            try:\n",
    "                # Coleta imagem e descrição da imagem, se disponíveis\n",
    "                img = driver.find_element('xpath', '/html/body/main/div/div/div[1]/div/section/div[2]/div/div[1]/figure/div/img').get_attribute('src')\n",
    "                descrimg = driver.find_element('xpath', '/html/body/main/div/div/div[1]/div/section/div[2]/div/div[1]/figure/div/img').get_attribute('alt')\n",
    "            except:\n",
    "                img = \"Sem imagem\"\n",
    "                descrimg = \"Sem descrição\"\n",
    "            \n",
    "            # Coleta o conteúdo da notícia\n",
    "            conteudo1 = driver.find_elements('xpath', '/html/body/main/div/div/div[1]/div/section/div[2]/div//p | /html/body/main/div/div/div[1]/div/section/div[2]/div//h2 | /html/body/main/div/div/div[1]/div/section/div[2]/div//ul | /html/body/main/div/div/div[1]/div/section/div[2]/div//blockquote | /html/body/main/div/div/div[1]/div/section/div[2]/div//span')\n",
    "\n",
    "            # Filtra o texto dos elementos, removendo conteúdos vazios\n",
    "            conteudo_texto = [element.text for element in conteudo1 if element.text.strip()]\n",
    "            \n",
    "            # Cria um dicionário com as informações da notícia\n",
    "            noticia = {\n",
    "                \"titulo\": titulo,\n",
    "                \"subtitulo\": subtitulo,\n",
    "                \"autor\": autor,\n",
    "                \"img\": img,\n",
    "                \"descrimg\": descrimg,\n",
    "                \"conteudo\": conteudo_texto\n",
    "            }\n",
    "\n",
    "            # Adiciona a nova notícia ao array de notícias\n",
    "            noticias.append(noticia)\n",
    "\n",
    "            # Salva o arquivo JSON com a nova notícia imediatamente\n",
    "            with open(json_file, 'w', encoding='utf-8') as file:\n",
    "                json.dump(noticias, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"\\nNotícia adicionada ao JSON - {titulo}\")\n",
    "            print(\"==========================================================================================\")\n",
    "            \n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        else:\n",
    "            print(f\"Notícia '{titulo}' já existe no arquivo. Ignorando...\")\n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "\n",
    "        # Se o código for executado sem exceções, sai do loop\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro encontrado: {e}\")\n",
    "        print(\"Tentando novamente...\\n\")\n",
    "        time.sleep(3)  # Espera 3 segundos antes de tentar novamente\n",
    "\n",
    "if tentativa == max_tentativas:\n",
    "    print(\"Número máximo de tentativas atingido. Encerrando o programa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentativa 1 de 2\n",
      "\n",
      "Notícia adicionada ao JSON - Neymar gera festa em treino do Al-Hilal com gol; veja vídeo\n",
      "==========================================================================================\n",
      "BUSCANDO PRÓXIMO SITE... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define o número máximo de tentativas\n",
    "max_tentativas = 2\n",
    "tentativa = 0\n",
    "\n",
    "while tentativa < max_tentativas:\n",
    "    try:\n",
    "        tentativa += 1\n",
    "        print(f\"Tentativa {tentativa} de {max_tentativas}\")\n",
    "\n",
    "        # Extrai os títulos já presentes no arquivo para verificar notícias duplicadas\n",
    "        titulos_existentes = {noticia['titulo'] for noticia in noticias}\n",
    "\n",
    "        # Acessa a página principal de esportes do IG\n",
    "        driver.get(\"https://esporte.ig.com.br/futebol/internacional/\")\n",
    "        time.sleep(2)  # Aguardar o carregamento da página inicial\n",
    "\n",
    "        # Localiza o link da notícia principal e acessa\n",
    "        try:\n",
    "            link = driver.find_element('xpath', '/html/body/main/div/div[1]/div/div/div[2]/div/div/div/ul[1]/li[1]/a').get_attribute('href')\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao tentar encontrar o link da notícia: {e}\")\n",
    "            print(\"Tentando acessar um link alternativo...\")\n",
    "            link = driver.find_element('xpath', '/html/body/main/div/div[1]/div/div[2]/div/div/div/div/ul[1]/div[2]/a').get_attribute('href')\n",
    "            continue  # Pula para a próxima tentativa\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(1)  # Aguardar o carregamento da página da notícia\n",
    "\n",
    "        # Coleta o título da notícia\n",
    "        titulo = driver.find_element('xpath', '/html/body/div[3]/div/div[1]/h1').get_attribute('innerText')\n",
    "\n",
    "        # Verifica se o título já está no arquivo JSON\n",
    "        if titulo not in titulos_existentes:\n",
    "            # Se a notícia não estiver no arquivo, coleta o restante das informações\n",
    "            subtitulo = driver.find_element('xpath', '/html/body/div[3]/div/div[1]/h2').get_attribute('innerText')\n",
    "            autor = driver.find_element('xpath', '/html/body/div[3]/div/div[4]/div/div').get_attribute('innerText')\n",
    "            \n",
    "            try:\n",
    "                # Coleta imagem e descrição da imagem, se disponíveis\n",
    "                img = driver.find_element('xpath', '/html/body/main/div/div/div[1]/div/section/div[2]/div/div[1]/figure/div/img').get_attribute('src')\n",
    "                descrimg = driver.find_element('xpath', '/html/body/main/div/div/div[1]/div/section/div[2]/div/div[1]/figure/div/img').get_attribute('alt')\n",
    "            except:\n",
    "                img = \"Sem imagem\"\n",
    "                descrimg = \"Sem descrição\"\n",
    "            \n",
    "            # Coleta o conteúdo da notícia\n",
    "            conteudo1 = driver.find_elements('xpath', '/html/body/main/div/div/div[1]/div/section/div[2]/div//p | /html/body/main/div/div/div[1]/div/section/div[2]/div//h2 | /html/body/main/div/div/div[1]/div/section/div[2]/div//ul | /html/body/main/div/div/div[1]/div/section/div[2]/div//blockquote | /html/body/main/div/div/div[1]/div/section/div[2]/div//span')\n",
    "\n",
    "            # Filtra o texto dos elementos, removendo conteúdos vazios\n",
    "            conteudo_texto = [element.text for element in conteudo1 if element.text.strip()]\n",
    "            \n",
    "            # Cria um dicionário com as informações da notícia\n",
    "            noticia = {\n",
    "                \"titulo\": titulo,\n",
    "                \"subtitulo\": subtitulo,\n",
    "                \"autor\": autor,\n",
    "                \"img\": img,\n",
    "                \"descrimg\": descrimg,\n",
    "                \"conteudo\": conteudo_texto\n",
    "            }\n",
    "\n",
    "            # Adiciona a nova notícia ao array de notícias\n",
    "            noticias.append(noticia)\n",
    "\n",
    "            # Salva o arquivo JSON com a nova notícia imediatamente\n",
    "            with open(json_file, 'w', encoding='utf-8') as file:\n",
    "                json.dump(noticias, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"\\nNotícia adicionada ao JSON - {titulo}\")\n",
    "            print(\"==========================================================================================\")\n",
    "            \n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        else:\n",
    "            print(f\"Notícia '{titulo}' já existe no arquivo. Ignorando...\")\n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "\n",
    "        # Se o código for executado sem exceções, sai do loop\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro encontrado: {e}\")\n",
    "        print(\"Tentando novamente...\\n\")\n",
    "        time.sleep(3)  # Espera 3 segundos antes de tentar novamente\n",
    "\n",
    "if tentativa == max_tentativas:\n",
    "    print(\"Número máximo de tentativas atingido. Encerrando o programa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentativa 1 de 2\n",
      "\n",
      "Notícia adicionada ao JSON - Brasil vence a Bolívia no sufoco e ganha fôlego no Sul-Americano Sub-20\n",
      "==========================================================================================\n",
      "BUSCANDO PRÓXIMO SITE... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define o número máximo de tentativas\n",
    "max_tentativas = 2\n",
    "tentativa = 0\n",
    "\n",
    "while tentativa < max_tentativas:\n",
    "    try:\n",
    "        tentativa += 1\n",
    "        print(f\"Tentativa {tentativa} de {max_tentativas}\")\n",
    "\n",
    "        # Extrai os títulos já presentes no arquivo para verificar notícias duplicadas\n",
    "        titulos_existentes = {noticia['titulo'] for noticia in noticias}\n",
    "\n",
    "        # Acessa a página da seleção do IG\n",
    "        driver.get(\"https://esporte.ig.com.br/futebol/selecaobrasileira/\")\n",
    "        time.sleep(2)  # Aguardar o carregamento da página inicial\n",
    "\n",
    "        # Localiza o link da notícia principal e acessa\n",
    "        try:\n",
    "            link = driver.find_element('xpath', '/html/body/main/div/div[1]/div/div/div[2]/div/div/div/ul[1]/li[1]/a').get_attribute('href')\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao tentar encontrar o link da notícia: {e}\")\n",
    "            print(\"Tentando acessar um link alternativo...\")\n",
    "            link = driver.find_element('xpath', '/html/body/main/div/div[1]/div/div[2]/div/div/div/div/ul[1]/div[2]/a').get_attribute('href')\n",
    "            continue  # Pula para a próxima tentativa\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(1)  # Aguardar o carregamento da página da notícia\n",
    "\n",
    "        # Coleta o título da notícia\n",
    "        titulo = driver.find_element('xpath', '/html/body/div[3]/div/div[1]/h1').get_attribute('innerText')\n",
    "\n",
    "        # Verifica se o título já está no arquivo JSON\n",
    "        if titulo not in titulos_existentes:\n",
    "            # Se a notícia não estiver no arquivo, coleta o restante das informações\n",
    "            subtitulo = driver.find_element('xpath', '/html/body/div[3]/div/div[1]/h2').get_attribute('innerText')\n",
    "            autor = driver.find_element('xpath', '/html/body/div[3]/div/div[4]/div/div').get_attribute('innerText')\n",
    "            \n",
    "            try:\n",
    "                # Coleta imagem e descrição da imagem, se disponíveis\n",
    "                img = driver.find_element('xpath', '/html/body/main/div/div/div[1]/div/section/div[2]/div/div[1]/figure/div/img').get_attribute('src')\n",
    "                descrimg = driver.find_element('xpath', '/html/body/main/div/div/div[1]/div/section/div[2]/div/div[1]/figure/div/img').get_attribute('alt')\n",
    "            except:\n",
    "                img = \"Sem imagem\"\n",
    "                descrimg = \"Sem descrição\"\n",
    "            \n",
    "            # Coleta o conteúdo da notícia\n",
    "            conteudo1 = driver.find_elements('xpath', '/html/body/main/div/div/div[1]/div/section/div[2]/div//p | /html/body/main/div/div/div[1]/div/section/div[2]/div//h2 | /html/body/main/div/div/div[1]/div/section/div[2]/div//ul | /html/body/main/div/div/div[1]/div/section/div[2]/div//blockquote | /html/body/main/div/div/div[1]/div/section/div[2]/div//span')\n",
    "\n",
    "            # Filtra o texto dos elementos, removendo conteúdos vazios\n",
    "            conteudo_texto = [element.text for element in conteudo1 if element.text.strip()]\n",
    "            \n",
    "            # Cria um dicionário com as informações da notícia\n",
    "            noticia = {\n",
    "                \"titulo\": titulo,\n",
    "                \"subtitulo\": subtitulo,\n",
    "                \"autor\": autor,\n",
    "                \"img\": img,\n",
    "                \"descrimg\": descrimg,\n",
    "                \"conteudo\": conteudo_texto\n",
    "            }\n",
    "\n",
    "            # Adiciona a nova notícia ao array de notícias\n",
    "            noticias.append(noticia)\n",
    "\n",
    "            # Salva o arquivo JSON com a nova notícia imediatamente\n",
    "            with open(json_file, 'w', encoding='utf-8') as file:\n",
    "                json.dump(noticias, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"\\nNotícia adicionada ao JSON - {titulo}\")\n",
    "            print(\"==========================================================================================\")\n",
    "            \n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        else:\n",
    "            print(f\"Notícia '{titulo}' já existe no arquivo. Ignorando...\")\n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "\n",
    "        # Se o código for executado sem exceções, sai do loop\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro encontrado: {e}\")\n",
    "        print(\"Tentando novamente...\\n\")\n",
    "        time.sleep(3)  # Espera 3 segundos antes de tentar novamente\n",
    "\n",
    "if tentativa == max_tentativas:\n",
    "    print(\"Número máximo de tentativas atingido. Encerrando o programa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentativa 1 de 2\n",
      "\n",
      "Notícia adicionada ao JSON - Brasil vence a Bolívia no sufoco e ganha fôlego no Sul-Americano Sub-20\n",
      "==========================================================================================\n",
      "BUSCANDO PRÓXIMO SITE... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define o número máximo de tentativas\n",
    "max_tentativas = 2\n",
    "tentativa = 0\n",
    "\n",
    "while tentativa < max_tentativas:\n",
    "    try:\n",
    "        tentativa += 1\n",
    "        print(f\"Tentativa {tentativa} de {max_tentativas}\")\n",
    "\n",
    "        # Extrai os títulos já presentes no arquivo para verificar notícias duplicadas\n",
    "        titulos_existentes = {noticia['titulo'] for noticia in noticias}\n",
    "\n",
    "        # Acessa a página do onefootball\n",
    "        driver.get(\"https://onefootball.com/pt-br/inicio\")\n",
    "        time.sleep(2)  # Aguardar o carregamento da página inicial\n",
    "\n",
    "        # Localiza o link da notícia principal e acessa\n",
    "        try:\n",
    "            d = driver.find_element('xpath', '/html/body/div[1]/main/div/div/div[4]/div/section/ul/li[2]/article/a[2]/p[1]/span[1]')\n",
    "            link = driver.find_element('xpath', '/html/body/div[1]/main/div/div/div[4]/div/section/ul/li[3]/article/a[2]').get_attribute('href')\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                link = driver.find_element('xpath', '/html/body/div[1]/main/div/div/div[4]/div/section/ul/li[2]/article/a[1]').get_attribute('href')\n",
    "            except:\n",
    "                print(f\"Erro ao tentar encontrar o link da notícia: {e}\")\n",
    "                print(\"Tentando acessar um link alternativo...\")\n",
    "                link = driver.find_element('xpath', '/html/body/div[1]/main/div/div/div[4]/div/section/ul/li[2]/article/a[2]').get_attribute('href')\n",
    "                continue  # Pula para a próxima tentativa\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(1)  # Aguardar o carregamento da página da notícia\n",
    "\n",
    "        # Coleta o título da notícia\n",
    "        titulo = driver.find_element('xpath', '/html/body/div[1]/main/div/div[1]/div[3]/div/article/div[1]/div[2]/h2').get_attribute('innerText')\n",
    "\n",
    "        # Verifica se o título já está no arquivo JSON\n",
    "        if titulo not in titulos_existentes:\n",
    "            # Se a notícia não estiver no arquivo, coleta o restante das informações\n",
    "            autor = driver.find_element('xpath', '/html/body/div[1]/main/div/div[1]/div[3]/div/article/div[1]/div[2]/div[1]/div').get_attribute('innerText')\n",
    "            \n",
    "            try:\n",
    "                # Coleta imagem e descrição da imagem, se disponíveis\n",
    "                img = driver.find_element('xpath', '/html/body/div[1]/main/div/div[1]/div[3]/div/article/div[2]/div/picture/img').get_attribute('src')\n",
    "                descrimg = driver.find_element('xpath', '/html/body/div[1]/main/div/div[1]/div[3]/div/article/div[2]/div/picture/img').get_attribute('alt')\n",
    "            except:\n",
    "                img = \"Sem imagem\"\n",
    "                descrimg = \"Sem descrição\"\n",
    "            \n",
    "            # Coleta o conteúdo da notícia\n",
    "            conteudo1 = driver.find_elements(\n",
    "                'xpath',\n",
    "                '''\n",
    "                /html/body/div[1]/main/div/div[1]/div[4]/div[1]/div\n",
    "                //p[not(ancestor::section)] |\n",
    "                /html/body/div[1]/main/div/div[1]/div[4]/div[1]/div\n",
    "                //h2[not(ancestor::section)] |\n",
    "                /html/body/div[1]/main/div/div[1]/div[4]/div[1]/div\n",
    "                //ul[not(ancestor::section)] |\n",
    "                /html/body/div[1]/main/div/div[1]/div[4]/div[1]/div\n",
    "                //blockquote[not(ancestor::section)] |\n",
    "                /html/body/div[1]/main/div/div[1]/div[4]/div[1]/div\n",
    "                //span[not(ancestor::section)]\n",
    "                '''\n",
    "            )\n",
    "\n",
    "\n",
    "            # Filtra o texto dos elementos, removendo conteúdos vazios\n",
    "            conteudo_texto = [element.text for element in conteudo1 if element.text.strip()]\n",
    "            \n",
    "            # Cria um dicionário com as informações da notícia\n",
    "            noticia = {\n",
    "                \"titulo\": titulo,\n",
    "                \"autor\": autor,\n",
    "                \"img\": img,\n",
    "                \"descrimg\": descrimg,\n",
    "                \"conteudo\": conteudo_texto\n",
    "            }\n",
    "\n",
    "            # Adiciona a nova notícia ao array de notícias\n",
    "            noticias.append(noticia)\n",
    "\n",
    "            # Salva o arquivo JSON com a nova notícia imediatamente\n",
    "            with open(json_file, 'w', encoding='utf-8') as file:\n",
    "                json.dump(noticias, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f\"\\nNotícia adicionada ao JSON - {titulo}\")\n",
    "            print(\"==========================================================================================\")\n",
    "            \n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "        else:\n",
    "            print(f\"Notícia '{titulo}' já existe no arquivo. Ignorando...\")\n",
    "            print(\"BUSCANDO PRÓXIMO SITE... \\n\")\n",
    "\n",
    "        # Se o código for executado sem exceções, sai do loop\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro encontrado: {e}\")\n",
    "        print(\"Tentando novamente...\\n\")\n",
    "        time.sleep(3)  # Espera 3 segundos antes de tentar novamente\n",
    "\n",
    "if tentativa == max_tentativas:\n",
    "    print(\"Número máximo de tentativas atingido. Encerrando o programa.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
